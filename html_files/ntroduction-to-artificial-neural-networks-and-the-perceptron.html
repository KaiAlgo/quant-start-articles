
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="google-site-verification" content="wl3-8ed1QZjI0iYZMv10zoZWYElkMObTfwLlWIj9cpA" />
    <meta name="description" content="In this article we begin our discussion of artificial neural networks (ANN). We first motivate the need for a deep learning based approach within quantitative finance. Then we outline one of the most elementary neural networks known as the perceptron. We discuss the architecture of the perceptron and its ability to function as a supervised linear classifier, using step function based activation functions.">

    <link rel="icon" href="/static/images/favicon.png">

    <title>Introduction to Artificial Neural Networks and the Perceptron | QuantStart</title>
    
    
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900&display=swap" rel="stylesheet"> 
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900&display=swap" rel="stylesheet"> 
<link href="/static/css/bootstrap.min.css" rel="stylesheet">
<link href="/static/css/prism.css" rel="stylesheet">
<link href="/static/css/qs.css?v=10" rel="stylesheet">
    
  </head>

  <body>
    <header class="header covered-header" style="background-image: linear-gradient(rgba(0, 0, 0, 0.8), rgba(0, 0, 0, 0.8)), url(https://quantstartmedia.s3.amazonaws.com/images/article-images/article-backgrounds/introduction-to-artificial-neural-networks-and-the-perceptron.jpg);">
  
<nav class="nav">
  <div class="container nav-container">
    <div class="nav-row row d-flex justify-content-between align-items-center">
      <div class="col-2">
        <ul class="nav-items justify-content-end small-capitals align-items-center">
          <li class="nav-item">
            <a class="link-fade" href="/">QuantStart</a>
          </li>
        </ul>
      </div>
      <div class="col-auto col-logo">
        <ul id="top-nav-menu" class="nav-items justify-content-end align-items-center">
          
          <li class="nav-item">
            <a class="link-fade" href="/qsalpha/">QSAlpha</a>
          </li>
          
          
          <li class="nav-item">
            <a class="link-fade" href="/quantcademy/">Quantcademy</a>
          </li>
          
          <li id="menu-link-ebooks" class="nav-item">
            <a class="link-fade" href="#">Books</a>
            <div id="menu-pane-ebooks" class="nav-items menu-dropdown-pane">
              <div class="nav-item">
                <a class="link-fade d-block ml-3 mr-3 my-3 mt-4" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a>
              </div>
              <div class="nav-item">
                <a class="link-fade d-block ml-3 mr-3 my-3 mt-4" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a>
              </div>
              <div class="nav-item">
                <a class="link-fade d-block ml-3 mr-3 my-3 mt-4" href="/cpp-for-quantitative-finance-ebook/">C++ For Quantitative Finance</a>
              </div>
            </div>
          </li>
          <li class="nav-item">
            <a class="link-fade" href="/qstrader/">QSTrader</a>
          </li>
          <li class="nav-item">
            <a class="link-fade" href="/articles/">Articles</a>
          </li>
          
          <li class="nav-item">
            <a class="link-fade" href="/members/login/">Login</a>
          </li>
          
        </ul>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
      </div>
    </div>
  </div>
</nav>

<nav id="mobile-nav" class="mobile-nav text-left">
  <div class="container">
    <ul class="mt-4 ml-3 mobile-nav-menu">
      <li class="nav-item">
        <a class="link-fade d-block" href="/">QuantStart</a>
      </li>

      
      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/qsalpha/">QSAlpha</a>
      </li>
      

      
      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/quantcademy/">Quantcademy</a>
      </li>
      

      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="#">Books</a>
      </li>
      <li class="nav-item sub-item">
        <a class="link-fade d-block ml-3" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a>
      </li>
      <li class="nav-item sub-item">
        <a class="link-fade d-block ml-3" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a>
      </li>
      <li class="nav-item sub-item">
        <a class="link-fade d-block ml-3" href="/cpp-for-quantitative-finance-ebook/">C++ For Quantitative Finance</a>
      </li>

      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/qstrader/">QSTrader</a>
      </li>

      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/articles/">Articles</a>
      </li>

      
      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/members/login/">Login</a>
      </li>
      
    </ul>
    <button class="nav-toggle mobile-nav-close">
      <svg id="mobile-nav-close-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
        <path d="M19.77,5.63,13.41,12l6.36,6.37a1,1,0,0,1-1.41,1.41L12,13.41,5.63,19.77a1,1,0,0,1-1.44-1.39l0,0L10.58,12,4.21,5.63a1,1,0,0,1,0-1.42,1,1,0,0,1,1.41,0l0,0L12,10.58l6.37-6.37a1,1,0,0,1,1.41,0A1,1,0,0,1,19.77,5.63Z"></path>
      </svg>
    </button>
  </div>
</nav>

  <div class="container hero-container">
    <section class="mt-5 mb-4">
      <div class="row justify-content-center">
        <div class="col-12 text-center">
          <p class="hero">Introduction to Artificial Neural Networks and the Perceptron</p>
          <p class="hero subhero">In this article we begin our discussion of artificial neural networks (ANN). We first motivate the need for a deep learning based approach within quantitative finance. Then we outline one of the most elementary neural networks known as the perceptron. We discuss the architecture of the perceptron and its ability to function as a supervised linear classifier, using step function based activation functions.</p>
        </div>
      </div>
    </section>
  </div>
</header>
    
<section class="container content-container">
  <div class="row">
    <div class="col-md-8 order-md-2">
      <section class="content article-content">
        
        
        <p>Quantitative finance is an extremely competitive field at the institutional level. Quant hedge funds vie for large allocations and must continually prove their worth in order to receive new assets under management. This drives a significant internal R&amp;D effort to achieve new sources of uncorrelated risk-adjusted returns for their clients. Funds and their trading desks must continually hunt for new sources of alpha. This can sometimes be found in new markets, with innovative data sources or with better predictive algorithms.</p>

<p>In recent years much of the quantitative hedge fund industry has turned its attention towards so-called <strong>alternative data</strong> as a means of generating new alpha. Such data is often in unstructured formats unsuitable for traditional time series based modelling approaches. Hence there is a strong push to leverage mechanisms that can extract value from these datasets and use them for predictive signal generation. One such field that has garnered significant attention in recent years is that of <strong>deep learning</strong>.</p>

<p><em>To discover more about deep learning please read our previous article: <a href="https://www.quantstart.com/articles/what-is-deep-learning/">What Is Deep Learning?</a></em></p>

<p>Deep learning hasn't escaped the attention of the practitioner retail quant either. The explosive rise of powerful open source software, along with the ever growing availability of data, combined with cheap access to computational hardware has lead many retail quants to pursue trading strategies powered by deep learning models.</p>

<p>Despite the relative simplicity of the APIs provided by modern deep learning frameworks there is still a substantial learning curve to be overcome in order to be able to successfully carry out quantitative trading research using deep learning approaches.</p>

<p><img src="https://quantstartmedia.s3.amazonaws.com/images/background-images/about-banner-network-binary.jpg"></p>

<p>As with any complex predictive model it is insufficient to simply 'copy and paste' open source model code and hope to generate a solid trading strategy. Instead a good understanding of the underlying models are required in order to avoid common pitfalls such as overfitting.</p>

<p>In this new series of articles we are going to explore deep learning models, first by studying the theory of the common models and subsequently by providing robust implementations that can be utilised and extended for your own trading purposes.</p>

<p>It is common for many deep learning tutorials to jump straight into code. While this is a useful learning approach for relatively simple examples, such as classifying objects in images, it is less appropriate in the realm of quantitative finance, where model errors can lead to significant unprofitability.</p>

<p>For this reason QuantStart will emphasise both theory and practice in order to provide a well-rounded understanding of the field and to help mitigate trading losses by deploying poorly constructed models.</p>

<p>This article will begin by introducing <strong>artificial neural network</strong> (ANN) models. It will discuss how they are inspired by biological neural networks. Attention will then turn to one of the earliest neural network models, known as the <strong>perceptron</strong>.</p>

<p>In future articles we will use the perceptron model as a 'building block' towards the construction of more sophisticated deep neural networks such as <strong>multi-layer perceptrons</strong> (MLP), demonstrating their power on some non-trivial machine learning problems.</p>

<h2>Artificial Neural Networks</h2>

<p>Deep learning may seem like an extremely modern field but research into the area began in the 1940s. In much the same way that birds have always motivated humans to develop heavier-than-air flight, the architecture of the human brain has motivated humans to try and replicate intelligence via similar neural structures.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Neuron">neuron</a> itself provided the inspiration for the development of networks of <em>computational neurons</em>, which can be combined to produce sophisticated computation even from fairly simple network architectures.</p>

<p>The arrangement of the human cerebral cortex has also been a significant motivator in certain deep neural network architectures such as the Convolutional Neural Network (CNN), which will be the focus of future articles.</p>

<p style="text-align:center">
  <img src="https://s3.amazonaws.com/quantstartmedia/images/qs-deep-learning-alexnet-architecture.png" width="100%">
  <br><strong>"AlexNet" Convolutional Neural Network architecture</strong><sup><a href="#ref-krizhevsky2012">[4]</a></sup>
</p>

<p>Research on networks of computational neurons, or artificial neural networks has been characterised by periods of intense development and funding along with relatively dormant periods known as 'AI Winters' where the promises of such technology often never lived up to the current hype.</p>

<p>In part this can be attributed to insufficiently complex models that were difficult to train in a reasonable time frame. The expense of obtaining, storing and processing the large quantities of data required to obtain good results was another contributing factor.</p>

<p>In recent years the above challenges have largely been surmounted. This has driven explosive growth in ANN research. The advent of the <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">Graphics Processing Unit</a> (GPU) provided the mechanism for cheap training. The rise of the internet lead to staggering quantities of easily available data. Training algorithms have steadily improved, as have model architectures.</p>

<p>The confluence of these achievements has produced state-of-the-art results by deep learning models on many challenging problems previously considered intractable.</p>

<p>While the research history of artificial neural networks is a fascinating topic in its own right, our goal here is to utilise these tools as quantitative trading practitioners in order to generate superior risk-adjusted returns. Such historical developments are out of scope for this article.</p>

<p>For those who wish to delve more deeply into the historical developments of artificial neural networks, please see the section <em>Historical Trends in Deep Learning</em> within the <em>Deep Learning</em><sup><a href="#ref-goodfellow2016">[1]</a></sup> book.</p>

<p>We will begin our discussion of ANNs via one of the simplest possible models known as the perceptron.</p>

<h2>The Perceptron</h2>

<p>In this section we are going to introduce the perceptron<sup><a href="#ref-rosenblatt1958">[2]</a></sup>. It is one of the earliest—and most elementary—artificial neural network models. The perceptron is extremely simple by modern deep learning model standards. However the concepts utilised in its design apply more broadly to sophisticated deep network architectures.</p>

<p>The perceptron is a supervised learning binary classification algorithm, originally developed by Frank Rosenblatt in 1957. It categorises input data into one of two separate states based a training procedure carried out on prior input data.</p>

<p style="text-align:center;"><img src="https://quantstartmedia.s3.amazonaws.com/images/article-images/articles/introduction-to-artificial-neural-networks-and-the-perceptron/perceptron.png"><caption><strong>The Perceptron</strong></caption></p>

<p>The perceptron attempts to partition the input data via a linear decision boundary. A similar procedure is carried out by another supervised learning algorithm known as <strong>support vector classifiers</strong>, which you can read about in our detailed article <a href="https://www.quantstart.com/articles/Support-Vector-Machines-A-Guide-for-Beginners/">here</a>.</p>

<p>The perceptron works by taking a set of scalar input features, along with a constant 'bias' term and assigning weights to these inputs. The <em>linear combination</em> of the weights and inputs are taken. This linear combination is then fed through an <strong>activation function</strong> that determines which state (or class) the set of inputs belongs to.</p>

<h3>Activation Functions for the Perceptron</h3>

<p>In this case of the perceptron model the chosen activation function is a <a href="https://en.wikipedia.org/wiki/Step_function">step function</a> that returns one of two distinct values (three in the case of the Sign function below) depending upon the value of the linear combination.</p>

<p>Common choices for the step function in perceptrons are the <a href="https://en.wikipedia.org/wiki/Heaviside_step_function">Heaviside function</a> and the <a href="https://en.wikipedia.org/wiki/Sign_function">Sign function</a>.</p>

<p>The Heaviside function (named after <a href="https://en.wikipedia.org/wiki/Oliver_Heaviside">Oliver Heaviside</a>) is given below:</p>

<p>
\begin{eqnarray}
h(z) = \begin{cases}
  0 & \text{if $z < 0$} \\
  1 & \text{if $z \geq 0$}
\end{cases}
\end{eqnarray}
</p>

<p>It says that if the provided linear combination $z$ is less than 0 then simply return 0, otherwise return 1.</p>

<p>The Sign function is given below:</p>

<p>
\begin{eqnarray}
\text{sgn}(z) = \begin{cases}
  -1 & \text{if $z < 0$} \\
  0 & \text{if $z = 0$} \\
  1 & \text{if $z > 0$}
\end{cases}
\end{eqnarray}
</p>

<p>It says that if the provided linear combination $z$ is less than 0 then return -1, if it is 0 then return 0, otherwise return +1.</p>

<h3>Algorithm for the Perceptron</h3>

<p>The mathematical procedure for determining the class label of a provided set of input data is as follows:</p>

<ol>
  <li>For an input vector ${\bf x}$, with components given by $x_i$, $i \in \{1,\ldots,n\}$ take the <a href="https://en.wikipedia.org/wiki/Dot_product">inner product</a> of ${\bf x}$ and the weight vector ${\bf w}$ to produce the weighted sum of inputs ${\bf x}^T {\bf w}$.</li>
  <li>Add the <em>bias term</em>, $b$ to this weighted sum to get $z = {\bf x}^T {\bf w} + b$.</li>
  <li>Apply the appropriate step function to $z$ in order to determine the class label of the inputs.</li>
</ol>

<p>The algorithm for the perceptron, when utilising the Heaviside activation function is summarised in the following function:</p>

<p>
\begin{eqnarray}
f(z) = \begin{cases}
  1 & \text{if ${\bf x}^T {\bf w} + b > 0$} \\
  0 & \text{otherwise} 
\end{cases}
\end{eqnarray}
</p>

<p>This simply says that if the weighted sum of the inputs (including the bias) exceeds zero then classify the input as state label 1, otherwise classify it as state label 0.</p>

<p>Note that some references will add the bias term into the weight vector ${\bf w}$ by adding a $w_0$ component. To make this work it will be necessary to add an $x_0$ component to the input vector, which is simply always set to one: $x_0=1$. It is then possible to write the algorithm as:</p>

<p>
\begin{eqnarray}
f(z) = \begin{cases}
  1 & \text{if ${\bf x}^T {\bf w} > 0$} \\
  0 & \text{otherwise} 
\end{cases}
\end{eqnarray}
</p>

<p>While this notation is certainly neater it should always be kept in mind that an implicit bias term exists as one of the components of this weighted sum.</p>

<h3>Why Do We Need a Bias Term?</h3>

<p>At this stage it may be worth asking why a bias term is needed at all? Geometrically it is possible to think of the linear decision boundary as a line (or hyperplane) that divides a region into two separate mutually exclusive subregions.</p>

<p>If a bias term was not present then this line (or hyperplane) would be forced to intersect the origin of the region. This could significantly reduce its predictive performance (or even render it useless) if the 'true' decision boundary did not lie on the origin. Hence it is always necessary to include a bias term to account for this possibility.</p>

<h2>Next Steps</h2>

<p>While the above classification algorithm provides a clear procedure on how to classify input data it does not provide any insight into how to set the weights (or bias) to allow the algorithm to proceed.</p>

<p>The next article in the series will discuss how perceptrons are <em>trained</em> so as to determine an optimal set of weights and biases for use in linear classification.</p>

<p>Once we have outlined the training procedure we will begin 'stacking' perceptrons together to form multi-layer perceptrons that can be used for regression and classification problems.</p>

<h2>References</h2>

<ul>
  <li><a name="ref-goodfellow2016" href="http://www.deeplearningbook.org/">[1] Goodfellow, I.J., Bengio, Y., Courville, A. (2016) <em>Deep Learning</em>, MIT Press</a></li>
  <li><a name="ref-rosenblatt1958" href="https://psycnet.apa.org/record/1959-09865-001">[2] Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. <em>Psychological Review</em>, <strong>65</strong>, 386-408.</a></li>
  <li><a name="ref-geron2019" href="https://amzn.to/3huiHbo">[3] Géron, A. (2019) <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Ed.</em>, O'Reilly Media</a></li>
  <li><a name="ref-krizhevsky2012" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">[4] Krizhevsky, A., Sutskever, I., Hinton, G. (2012) "ImageNet Classification with Deep Convolutional Neural Networks", <em>Advances in Neural Information Processing Systems 25 (NIPS 2012)</em></a></li>
</ul>
        
        
        <script async data-uid="6296c27f4b" src="https://weathered-brook-5281.ck.page/6296c27f4b/index.js"></script>
      </section>
    </div>
    <div class="col-md-4 book-card order-md-1">
      
<div class="sidebar-advert-container">
  <a href="/qsalpha/?ref=art">
    <img class="card-img-top" src="/static/images/qsalpha-sidebar-advert-small.png" alt="QSAlpha">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/qsalpha/?ref=art">QSAlpha</a></h3>
      <p class="card-text medium-text mb-3">Join the QSAlpha research platform that helps fill your strategy research pipeline, diversifies your portfolio and improves your risk-adjusted returns for increased profitability.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/qsalpha/?ref=art">Find Out More</a>
        </div>
      </div>
    </div>
  </div>

  <a href="/quantcademy/?ref=art">
    <img class="card-img-top" src="/static/images/quantcademy-sidebar-advert-small.png" alt="Quantcademy">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/quantcademy/?ref=art">The Quantcademy</a></h3>
      <p class="card-text medium-text mb-3">Join the Quantcademy membership portal that caters to the rapidly-growing retail quant trader community and learn how to increase your strategy profitability.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/quantcademy/?ref=art">Find Out More</a>
        </div>
      </div>
    </div>
  </div>

  <a href="/successful-algorithmic-trading-ebook/">
    <img class="card-img-top" src="/static/images/sat-sidebar-advert-small.png" alt="Successful Algorithmic Trading">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a></h3>
      <p class="card-text medium-text mb-3">How to find new trading strategy ideas and objectively assess them for your portfolio using a Python-based backtesting engine.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/successful-algorithmic-trading-ebook/">Find Out More</a>
        </div>
      </div>
    </div>
  </div>

  <a href="/advanced-algorithmic-trading-ebook/">
    <img class="card-img-top" src="/static/images/aat-sidebar-advert-small.png" alt="Advanced Algorithmic Trading">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a></h3>
      <p class="card-text medium-text mb-3">How to implement advanced trading strategies using time series analysis, machine learning and Bayesian statistics with R and Python.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/advanced-algorithmic-trading-ebook/">Find Out More</a>
        </div>
      </div>
    </div>
  </div>
</div>
    </div>
  </div>
</section>

    

<footer>
  <div class="container container-full">
    <section class="mt-1.5 mb-1">
      <div class="row">
        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">QuantStart</li>
            <li class="footer-list-link"><a class="link-fade" href="/about/">About</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/articles/">Articles</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/sitemap/">Sitemap</a></li>
          </ul>
        </div>

        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">Products</li>
            
            <li class="footer-list-link"><a class="link-fade" href="/qsalpha/">QSAlpha</a></li>
            
            
            <li class="footer-list-link"><a class="link-fade" href="/quantcademy/">Quantcademy</a></li>
            
            <li class="footer-list-link"><a class="link-fade" href="/qstrader/">QSTrader</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/cpp-for-quantitative-finance-ebook/">C++ For Quantitative Finance</a></li>
          </ul>
        </div>

        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">Legal</li>
            <li class="footer-list-link"><a class="link-fade" href="/privacy-policy/">Privacy Policy</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/terms-and-conditions/">Terms &amp; Conditions</a></li>
          </ul>
        </div>

        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">Social</li>
            <li class="footer-list-link"><a class="link-fade" href="https://twitter.com/quantstart">Twitter</a></li>
            <li class="footer-list-link"><a class="link-fade" href="https://www.youtube.com/channel/UCmVnnZ6Y2TrJtY1eQJN6kWA">YouTube</a></li>
          </ul>
        </div>
      </div>
    </section>

    <div class="row mb-1.5 mt-5">
      <div class="col-12 col-md-9 col-lg-8 col-xl-6">
        <div class="footer-copyright">
          <p>©2012-2023 QuarkGluon Ltd. All rights reserved.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

    
<script src="/static/js/jquery-3.2.1.min.js"></script>
<script src="/static/js/prism.js.min"></script>
<script src="/static/js/bootstrap.min.js"></script>
<script src="/static/js/nav.js"></script>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-5383959-5']);
  _gaq.push(['_trackPageview']);

  (function() {
  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


    
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="/static/js/highcharts/highcharts.js"></script>
<script type="text/javascript">
  num_colours = 10;
</script>
<script src="/static/js/statistics.js"></script>


  </body>
</html>
