
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="google-site-verification" content="wl3-8ed1QZjI0iYZMv10zoZWYElkMObTfwLlWIj9cpA" />
    <meta name="description" content="Vector Addition &quot;Hello World!&quot; Example with CUDA on Mac OSX">

    <link rel="icon" href="/static/images/favicon.png">

    <title>Vector Addition &quot;Hello World!&quot; Example with CUDA on Mac OSX | QuantStart</title>
    
    
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900&display=swap" rel="stylesheet"> 
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900&display=swap" rel="stylesheet"> 
<link href="/static/css/bootstrap.min.css" rel="stylesheet">
<link href="/static/css/prism.css" rel="stylesheet">
<link href="/static/css/qs.css?v=10" rel="stylesheet">
    
  </head>

  <body>
    <header class="header covered-header" style="background-image: linear-gradient(rgba(0, 0, 0, 0.8), rgba(0, 0, 0, 0.8)), url(https://quantstartmedia.s3.amazonaws.com/images/article-images/article-backgrounds/default-bg.jpg);">
  
<nav class="nav">
  <div class="container nav-container">
    <div class="nav-row row d-flex justify-content-between align-items-center">
      <div class="col-2">
        <ul class="nav-items justify-content-end small-capitals align-items-center">
          <li class="nav-item">
            <a class="link-fade" href="/">QuantStart</a>
          </li>
        </ul>
      </div>
      <div class="col-auto col-logo">
        <ul id="top-nav-menu" class="nav-items justify-content-end align-items-center">
          
          <li class="nav-item">
            <a class="link-fade" href="/qsalpha/">QSAlpha</a>
          </li>
          
          
          <li class="nav-item">
            <a class="link-fade" href="/quantcademy/">Quantcademy</a>
          </li>
          
          <li id="menu-link-ebooks" class="nav-item">
            <a class="link-fade" href="#">Books</a>
            <div id="menu-pane-ebooks" class="nav-items menu-dropdown-pane">
              <div class="nav-item">
                <a class="link-fade d-block ml-3 mr-3 my-3 mt-4" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a>
              </div>
              <div class="nav-item">
                <a class="link-fade d-block ml-3 mr-3 my-3 mt-4" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a>
              </div>
              <div class="nav-item">
                <a class="link-fade d-block ml-3 mr-3 my-3 mt-4" href="/cpp-for-quantitative-finance-ebook/">C++ For Quantitative Finance</a>
              </div>
            </div>
          </li>
          <li class="nav-item">
            <a class="link-fade" href="/qstrader/">QSTrader</a>
          </li>
          <li class="nav-item">
            <a class="link-fade" href="/articles/">Articles</a>
          </li>
          
          <li class="nav-item">
            <a class="link-fade" href="/members/login/">Login</a>
          </li>
          
        </ul>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
      </div>
    </div>
  </div>
</nav>

<nav id="mobile-nav" class="mobile-nav text-left">
  <div class="container">
    <ul class="mt-4 ml-3 mobile-nav-menu">
      <li class="nav-item">
        <a class="link-fade d-block" href="/">QuantStart</a>
      </li>

      
      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/qsalpha/">QSAlpha</a>
      </li>
      

      
      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/quantcademy/">Quantcademy</a>
      </li>
      

      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="#">Books</a>
      </li>
      <li class="nav-item sub-item">
        <a class="link-fade d-block ml-3" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a>
      </li>
      <li class="nav-item sub-item">
        <a class="link-fade d-block ml-3" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a>
      </li>
      <li class="nav-item sub-item">
        <a class="link-fade d-block ml-3" href="/cpp-for-quantitative-finance-ebook/">C++ For Quantitative Finance</a>
      </li>

      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/qstrader/">QSTrader</a>
      </li>

      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/articles/">Articles</a>
      </li>

      
      <li class="nav-item">
        <a class="link-fade d-block pt-3" href="/members/login/">Login</a>
      </li>
      
    </ul>
    <button class="nav-toggle mobile-nav-close">
      <svg id="mobile-nav-close-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
        <path d="M19.77,5.63,13.41,12l6.36,6.37a1,1,0,0,1-1.41,1.41L12,13.41,5.63,19.77a1,1,0,0,1-1.44-1.39l0,0L10.58,12,4.21,5.63a1,1,0,0,1,0-1.42,1,1,0,0,1,1.41,0l0,0L12,10.58l6.37-6.37a1,1,0,0,1,1.41,0A1,1,0,0,1,19.77,5.63Z"></path>
      </svg>
    </button>
  </div>
</nav>

  <div class="container hero-container">
    <section class="mt-5 mb-4">
      <div class="row justify-content-center">
        <div class="col-12 text-center">
          <p class="hero">Vector Addition &quot;Hello World!&quot; Example with CUDA on Mac OSX</p>
          <p class="hero subhero">Vector Addition &quot;Hello World!&quot; Example with CUDA on Mac OSX</p>
        </div>
      </div>
    </section>
  </div>
</header>
    
<section class="container content-container">
  <div class="row">
    <div class="col-md-8 order-md-2">
      <section class="content article-content">
        
        
        <p>In my <a href="http://www.quantstart.com/articles/Installing-Nvidia-CUDA-on-Mac-OSX-for-GPU-Based-Parallel-Computing">previous article</a> I explained how to install CUDA on OS X. Now it's time to start coding. However, I don't want to merely show you some piece of "ready-made" code. I would also like to also explain to you the basic concepts behind parallel programming and, specifically, GPU programming. Hence, in this article and in the following ones, I will pair some key theory with code examples.</p>

<p>Today I will explain how GPUs work and show you how to turn theory into practice through a basic <i>vector addition</i> script. I won't dwell upon theory too much but we need to know some basic parallel computing ideas before going ahead with some programming.</p>

<p>So let's start with the one million dollar question: <em>Why</em> parallelise? Well, I provided a motivating example in my previous article via the story about removal vans. Now I would like to give you some numbers to think about, as well as introducing the vector addition problem that we'll consider later on in this article.</p>

<p>We want to sum two one-dimensional vectors, A and B, containing 512 cells (numbers) each, with the result contained in a third vector, named C. This is considered by some to be the <a href="http://en.wikipedia.org/wiki/%22Hello,_world!%22_program">"Hello World"</a> example for CUDA.</p>

<p style="text-align:center;">
  <img width="400px" alt="Parallel vector addition" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0001.png"><br>
  <strong>Vector addition</strong>
</p>

<h3>Serial Process</h3>

<p>Let's say we have a fast CPU that can perform a simple addition in 1ns (nanosecond). We have two one-dimensional vectors with 512 elements each, so the CPU will compute the first addition, and then the second addition, and the third, and so on until it computes the 512th addition. Assuming that every other aspect of the calculation requires no time then it would take 512ns to get our vector, C, completely filled. Actually, we are making a restrictive assumption dealing with only 512 elements, but it is fine for large numbers. Later I'll go into more details.</p>

<h3>Parallel Process</h3>

<p>Now let's have a try with a GPU. Modern GPUs can have thousands of slower processors, so, as we have only 512 additions to do, we can do them all in parallel. As those processors are slower, let's assume that each will compute one addition in 10ns. But they are <strong>all</strong> doing it simultaneously, so the total time spent calculating our C vector is 10ns!</p>

<p>In conclusion, we can see that parallel computing needs more time to perform a single task, but can efficiently manage to do thousands of them at a time. So it's optimised for <strong>throughput</strong>. Otherwise, serial programming is far more efficient for the single task (in our example ten times faster!), and as such is optimised for <strong>latency</strong>.</p>

<p>This means that there isn't a single best approach, but we can choose the best method for each task we might need to carry out.</p>

<h3>Basic GPU computing</h3>

<p>There are two main types of <i>parallelism</i>: task parallelism and data parallelism. Sticking with our vector addition, let's say we have to sum multiple vectors. In this case, each addition <strong>C=A+B</strong> is a <strong>task</strong>. So, having vectors with 512 elements, we have to perform 512 operations on each task. Of course, we can parallelise both of them, and the latter is data parallelism. In this article I'll show you how to perform the latter, but I'll cover task parallelism in future.</p>

<p>The basic structure of a parallel program, as shown in the following picture, is composed of a serial part, a parallel part and then a final serial part. Also, communication between the CPU (host) and the GPU (device) is needed for memory allocation and data transfer.</p>

<p style="text-align:center;">
  <img width="400px" alt="Code flow" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0002.png"><br>
  <strong>Code flow</strong>
</p>

<p>When you launch a function which executes operations in parallel, you're launching what is known as a <strong>kernel</strong>. Each kernel has a task to complete and to do so it makes use of what are known as <strong>threads</strong>. We can consider a thread as a subtask (in our case, a single addition), which are grouped along with other threads in <strong>blocks</strong>. Blocks are grouped in <strong>grids</strong> and each block can contain up to 1024 threads (or 512 on older GPUs). We can launch in parallel as many blocks as our GPU can support. Also note that for maximising hardware efficiency the number of threads in a block should be a multiple of 32.</p>

<p style="text-align:center;">
  <img width="500px" alt="Kernel structure" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0002b.png"><br>
  <strong>Kernel structure</strong>
</p>

<h3>Vector addition</h3>

<p>What follows is a simple vector addition script (the complete code is at the end of this page). As we are concentrating primarily on the code, I'll show you how to carry this out using NVIDIA's Nsight environment (Eclipse edition). I believe this is a very useful resource for those who do not have terminal or command line experience. Those who have experience will not have trouble considering other IDEs!</p>

<p>In general, CUDA scripts can be coded in only one file (with extension <strong>.cu</strong>) but, for the sake of generality, I prefer to split kernel code and serial code in distinct files (C++ and CUDA, respectively). I find this very useful for more complex programs and I believe it's a good way to start "thinking in parallel".</p>

<p>The first thing we have to do is make a new project. So open <strong>Nsight</strong>, click on <strong>New&gt;CUDA C/C++ Project</strong>, type the project name and select <strong>CUDA Runtime Project</strong>, CUDA toolkit 6.0.</p>

<p style="text-align:center;">
  <img width="500px" style="border:1px solid #eee;" alt="New project on File menu" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0003.png"><br>
  <strong>New project on File menu</strong>
</p>

<p style="text-align:center;">
  <img width="500px" style="border:1px solid #eee;" alt="New Project window" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0004.png"><br>
  <strong>New Project window</strong>
</p>

<p>Now you have to choose you source folder name ("src" is fine) and check the box that matches your GPU compute capability. Mine is 3.0, so I checked only 3.0 on both of the lines.</p>

<p style="text-align:center;">
  <img width="450px" style="border:1px solid #eee;" alt="Select source folder and compute capability" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0005.png"><br>
  <strong>Select source folder and compute capability</strong>
</p>

<p>Now you should have a folder with the selected name, including two subfolders, "<strong>Includes</strong>" and "<strong>src</strong>". As we selected the Runtime Project you'll also have a "<strong>vector_addition.cu</strong>" file. Delete it by right-clicking and choosing <strong>Delete</strong>, as we don't need it.</p>

<p>Just a step more: Select this folder and click on the <strong>New Source File</strong> button at the top-left. As I said, I prefer to split CPU and GPU parts, so, after the name, also type "<strong>.cpp</strong>".</p>

<p style="text-align:center;">
  <img width="450px" style="border:1px solid #eee;" alt="New file button" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0006.png"><br>
  <strong>New file button</strong>
</p>

<p>You should have your .cpp file in your <strong>vector_addition/src</strong> folder. Open it and let's start coding!</p>

<strong>Includes and variables declaration</strong></p>

<p>First, let's include some libraries we'll use later in this script. So type</p>

<pre>
<code class="language-cpp">#include &lt;math.h&gt;
#include &lt;time.h&gt;
#include &lt;iostream&gt;
#include &lt;stdexcept&gt;
#include &quot;cuda_runtime.h&quot;
#include &quot;kernel.h&quot;</code>
</pre>

<p>and then declare the variables we need</p>

<pre>
<code class="language-cpp">// declare the vectors&#39; number of elements and their size in bytes
static const int n_el = 512;
static const size_t size = n_el * sizeof(float);

int main() {
  // declare and allocate input vectors h_A and h_B in the host (CPU) memory
  float* h_A = (float*)malloc(size);
  float* h_B = (float*)malloc(size);
  float* h_C = (float*)malloc(size);
  
  // declare device vectors in the device (GPU) memory
  float *d_A,*d_B,*d_C;</code>
</pre>

<p>h_A and h_B are the vectors we want to sum into h_C, while d_C is the vector in which we'll store the result. Note that I used the prefix <strong>h_</strong> or <strong>d_</strong>on every variable name. This is a good habit to discern <strong>host</strong> (CPU) variables from <strong>device</strong> (GPU) ones. Of course this is just my favourite form, but you may encounter programmers who prefer something like Host_a, a_host, a_h etc. Those are all equivalent conventions, so you can choose the one with which you're most comfortable. You can also just name them a, b, c, but always remember which variable to use within the host and which one on the device, or you will soon get into trouble!</p>

<p>Now we can initialise the vectors. I'll do it by filling them with $\sin$ and $\cos$ functions by using a <strong>for loop</strong>. Please remember that this time we're not seeking the most optimised code, we're simply learning at this stage.</p>

<pre>
<code class="language-cpp">  // initialize input vectors
  for (int i=0; i&lt;n_el; i++){
    h_A[i]=sin(i);
    h_B[i]=cos(i);
  }</code>
</pre>

<h3>Memory allocation and transfer</h3>

<p>Now we need to allocate the memory on the GPU for the vectors we declared before. We can do this by simply using the <strong>cudaMalloc</strong> function, which takes a variable and its size as inputs. So, for us it is given by:</p>

<pre>
<code class="language-cpp">  // allocate device vectors in the device (GPU) memory
  cudaMalloc(&amp;d_A, size);
  cudaMalloc(&amp;d_B, size);
  cudaMalloc(&amp;d_C, size);</code>
</pre>

<p>Now we'll use another CUDA function, which is necessary to transfer data between the host and the device. The function's name is cudaMemcpy and takes four parameters. The first and the second parameters are pointers to the destination location and the source location, respectively. The third parameter specifies their size (in bytes), while the fourth is a string which specifies the transfer path. For the latter, we have three choices:</p>

<ul>
  <li>cudaMemcpyHostToDevice</li>
  <li>cudaMemcpyDeviceToHost</li>
  <li>cudaMemcpyHostToHost</li>
</ul>

<p>that we can use depending on what we need to do. At first, as we need to transfer data from CPU to GPU, we'll use <strong>cudaMemcpyHostToDevice</strong>, using these two lines of code:</p>

<pre>
<code class="language-cpp">  // copy input vectors from the host (CPU) memory to the device (GPU) memory
  cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
  cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);</code>
</pre>

<p>This means that we are transferring from the <strong>h_A (host)</strong> location to <strong>d_A (device)</strong> location <strong>size</strong> bytes of data.</p>

<h3>Kernel function invocation</h3>

<p>As I've already mentioned a couple of times I prefer to split the CPU and GPU parts. In this script we don't launch the kernel directly but we just call the function containing it. We only need to write:</p>

<pre>
<code class="language-cpp">  // call kernel function
  sum(d_A, d_B, d_C, n_el);</code>
</pre>

<p>I'll show later how to write both this function and the actual kernel. Also, I'll show you how to check for errors in later articles.</p>

<h3>GPU to CPU and memory deallocation</h3>

<p>This is the final part of this script. We need to transfer our output vector <code>d_C</code> from the device to the host and then clean the memory by deallocating our variables from GPU's memory and deleting them from the CPU.</p>

<pre>
<code class="language-cpp">  // copy the output (results) vector from the device (GPU) memory to the host (CPU) memory
  cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);

  // free device memory
  cudaFree(d_A);
  cudaFree(d_B);
  cudaFree(d_C);

  // free host memory
  delete[] h_A;
  delete[] h_B;
  delete[] h_C;

  return cudaDeviceSynchronize();
}</code>
</pre>

<p>In the complete code below, you can also find a section that computes the cumulative error (if any!) of this vector addition, to check if everything went fine.</p>

<p>Our serial code is now finished. We just have to write the kernel.</p>

<h3>Kernel code</h3>

<p>First, we need a header file. So click on <strong>New&gt;Header File</strong> and when asked for a name, type <strong>kernel.h</strong>. This one is pretty easy to deal with, as we only need to declare our kernel function and a couple of more lines needed to check for errors.</p>

<pre>
<code class="language-cpp">// avoid definition redundancies
#ifndef KERNEL_CUH_
#define KERNEL_CUH_

void sum(const float* A, const float* B, float* C, int n_el);

#endif</code>
</pre>

<p>As you can see, the function only takes our three arrays and the number of elements they are composed of. In essence, it is just a normal function.</p>

<p>But eventually the kernel has to be written. Create the last file, as usual by going to <strong>New&gt;Source File</strong> on the menu or by clicking the specific button.</p>

<p>First, we have to include libraries and declare the kernel as follows:</p>

<pre>
<code class="language-cpp">#include &lt;math.h&gt;
#include &quot;cuda_runtime.h&quot;
#include &quot;kernel.h&quot;

// declare the kernel function
__global__ void kernel_sum(const float* A, const float* B, float* C, int n_el);</code>
</pre>

<p>Second, we have to declare the function used for kernel invocation. Again, it's not mandatory to have it, but it will be useful in more complex and/or longer programs.</p>

<pre>
<code class="language-cpp">// function which invokes the kernel
void sum(const float* A, const float* B, float* C, int n_el) {

  // declare the number of blocks per grid and the number of threads per block
  int threadsPerBlock,blocksPerGrid;

  // use 1 to 512 threads per block
  if (n_el&lt;512){
    threadsPerBlock = n_el;
    blocksPerGrid   = 1;
  } else {
    threadsPerBlock = 512;
    blocksPerGrid   = ceil(double(n_el)/double(threadsPerBlock));
  }</code>
</pre>

<p>As you can see, by now this function is only used to dynamically set the number of threads per block and blocks per grid.</p>

<p>What follows is the <strong>most important</strong> part in today's example. This is how the kernel is invoked </p>

<pre>
<code class="language-cpp">    // invoke the kernel
    kernel_sum&lt;&lt;&lt;blocksPerGrid,<WBR>threadsPerBlock&gt;&gt;&gt;(A, B, C, n_el);
}</code>
</pre>

<p>This means that the <strong>kernel_sum</strong> kernel will use <strong>blocksPerGrid</strong> number of blocks and <strong>threadsPerBlock</strong> number of threads to compute the vector addition. The <strong>if</strong> statement is needed to prevent multiple threads from accessing the same portion of memory (e.g. we have two blocks of 512 threads each but n_el is 515. In this case, without that condition, threads from 516 to 1024 could do some unexpected work).</p>

<pre>
<code class="language-cpp">// kernel
__global__ void kernel_sum(const float* A, const float* B, float* C, int n_el)
  // calculate the unique thread index
  int tid = blockDim.x * blockIdx.x + threadIdx.x;
  // perform tid-th elements addition
  if (tid < n_el) C[tid] = A[tid] + B[tid];
}</code>
</pre>

<p>This is the kernel, where the GPU magic happens. The element-wise addition is no different from every other function, but it's fundamental to understand how the GPU obtains its indexes. In this trivial example, we have one-dimensional vectors, so we just need to get the block index (<strong>blockDim.x * blockIdx.x</strong>) by using these built-in objects and sum the thread index (<strong>threadIdx.x</strong>) <strong>within </strong>the block to them.</p>

<p>Now click the <strong>Run</strong> button to launch your first GPU program!</p>

<p style="text-align:center;">
  <img width="500px" style="border:1px solid #eee;" alt="Run button" src="https://s3.amazonaws.com/quantstartmedia/images/qs-cuda-vector-0007.png"><br>
  <strong>Run button</strong>
</p>

<p>I hope this guide has been useful. In the next few articles I'll discuss useful topics such as checking for errors, performance measurements, makefiles etc. as well as more advanced concepts in parallel computing.</p>

<h3>Complete code</h3>

<h4>vector_addition.cpp</h4>

<pre>
<code class="language-cpp">#include &lt;math.h&gt;
#include &lt;time.h&gt;
#include &lt;iostream&gt;
#include &lt;stdexcept&gt;
#include &quot;cuda_runtime.h&quot;
#include &quot;kernel.h&quot;

// declare the vectors&#39; number of elements and their size in bytes
static const int n_el = 512;
static const size_t size = n_el * sizeof(float);

int main(){
  // declare and allocate input vectors h_A and h_B in the host (CPU) memory
  float* h_A = (float*)malloc(size);
  float* h_B = (float*)malloc(size);
  float* h_C = (float*)malloc(size);

  // declare device vectors in the device (GPU) memory
  float *d_A,*d_B,*d_C;

  // initialize input vectors
  for (int i=0; i&lt;n_el; i++){
    h_A[i]=sin(i);
    h_B[i]=cos(i);
  }

  // allocate device vectors in the device (GPU) memory
  cudaMalloc(&amp;d_A, size);
  cudaMalloc(&amp;d_B, size);
  cudaMalloc(&amp;d_C, size);

  // copy input vectors from the host (CPU) memory to the device (GPU) memory
  cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
  cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);

  // call kernel function
  sum(d_A, d_B, d_C, n_el);

  // copy the output (results) vector from the device (GPU) memory to the host (CPU) memory
  cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);
  // free device memory
  cudaFree(d_A);
  cudaFree(d_B);
  cudaFree(d_C);

  // compute the cumulative error
  double err=0;
  for (int i=0; i&lt;n_el; i++) {
    double diff=double((h_A[i]+h_B[i])-h_<WBR>C[i]);
    err+=diff*diff;
    // print results for manual checking.
    std::cout &lt;&lt; &quot;A+B: &quot; &lt;&lt; h_A[i]+h_B[i] &lt;&lt; &quot;\n&quot;;
    std::cout &lt;&lt; &quot;C: &quot; &lt;&lt; h_C[i] &lt;&lt; &quot;\n&quot;;
  }
  err=sqrt(err);
  std::cout &lt;&lt; &quot;err: &quot; &lt;&lt; err &lt;&lt; &quot;\n&quot;;

  // free host memory
  delete[] h_A;
  delete[] h_B;
  delete[] h_C;

  return cudaDeviceSynchronize();
}</code>
</pre>

<h4>Kernel.h</h4>

<pre>
<code class="language-cpp">// avoid definition redundancies
#ifndef KERNEL_CUH_
#define KERNEL_CUH_

void sum(const float* A, const float* B, float* C, int n_el);

#endif</code>
</pre>

<h4>Kernel.cu</h4>

<pre>
<code class="language-cpp">#include &lt;math.h&gt;
#include &quot;cuda_runtime.h&quot;
#include &quot;kernel.h&quot;

// declare the kernel function
__global__ void kernel_sum(const float* A, const float* B, float* C, int n_el);

// function which invokes the kernel
void sum(const float* A, const float* B, float* C, int n_el) {

  // declare the number of blocks per grid and the number of threads per block
  int threadsPerBlock,blocksPerGrid;

  // use 1 to 512 threads per block
  if (n_el&lt;512){
    threadsPerBlock = n_el;
    blocksPerGrid   = 1;
  } else {
    threadsPerBlock = 512;
    blocksPerGrid   = ceil(double(n_el)/double(threadsPerBlock));
  }

  // invoke the kernel
  kernel_sum&lt;&lt;&lt;blocksPerGrid,threadsPerBlock&gt;&gt;&gt;(A, B, C, n_el);
}

// kernel
__global__ void kernel_sum(const float* A, const float* B, float* C, int n_el)
{
  // calculate the unique thread index
  int tid = blockDim.x * blockIdx.x + threadIdx.x;
  // perform tid-th elements addition 
  if (tid < n_el) C[tid] = A[tid] + B[tid];
}</code>
</pre>
        
        
        <script async data-uid="6296c27f4b" src="https://weathered-brook-5281.ck.page/6296c27f4b/index.js"></script>
      </section>
    </div>
    <div class="col-md-4 book-card order-md-1">
      
<div class="sidebar-advert-container">
  <a href="/qsalpha/?ref=art">
    <img class="card-img-top" src="/static/images/qsalpha-sidebar-advert-small.png" alt="QSAlpha">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/qsalpha/?ref=art">QSAlpha</a></h3>
      <p class="card-text medium-text mb-3">Join the QSAlpha research platform that helps fill your strategy research pipeline, diversifies your portfolio and improves your risk-adjusted returns for increased profitability.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/qsalpha/?ref=art">Find Out More</a>
        </div>
      </div>
    </div>
  </div>

  <a href="/quantcademy/?ref=art">
    <img class="card-img-top" src="/static/images/quantcademy-sidebar-advert-small.png" alt="Quantcademy">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/quantcademy/?ref=art">The Quantcademy</a></h3>
      <p class="card-text medium-text mb-3">Join the Quantcademy membership portal that caters to the rapidly-growing retail quant trader community and learn how to increase your strategy profitability.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/quantcademy/?ref=art">Find Out More</a>
        </div>
      </div>
    </div>
  </div>

  <a href="/successful-algorithmic-trading-ebook/">
    <img class="card-img-top" src="/static/images/sat-sidebar-advert-small.png" alt="Successful Algorithmic Trading">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a></h3>
      <p class="card-text medium-text mb-3">How to find new trading strategy ideas and objectively assess them for your portfolio using a Python-based backtesting engine.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/successful-algorithmic-trading-ebook/">Find Out More</a>
        </div>
      </div>
    </div>
  </div>

  <a href="/advanced-algorithmic-trading-ebook/">
    <img class="card-img-top" src="/static/images/aat-sidebar-advert-small.png" alt="Advanced Algorithmic Trading">
  </a>
  <div class="card mb-4 box-shadow">
    <div class="card-body text-center">
      <h3 class="mb-3"><a class="link-fade" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a></h3>
      <p class="card-text medium-text mb-3">How to implement advanced trading strategies using time series analysis, machine learning and Bayesian statistics with R and Python.</p>
      <div class="d-flex justify-content-center align-items-center">
        <div class="btn-group">
          <a class="btn btn-padded btn-outline-primary btn-lg-cta" href="/advanced-algorithmic-trading-ebook/">Find Out More</a>
        </div>
      </div>
    </div>
  </div>
</div>
    </div>
  </div>
</section>

    

<footer>
  <div class="container container-full">
    <section class="mt-1.5 mb-1">
      <div class="row">
        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">QuantStart</li>
            <li class="footer-list-link"><a class="link-fade" href="/about/">About</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/articles/">Articles</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/sitemap/">Sitemap</a></li>
          </ul>
        </div>

        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">Products</li>
            
            <li class="footer-list-link"><a class="link-fade" href="/qsalpha/">QSAlpha</a></li>
            
            
            <li class="footer-list-link"><a class="link-fade" href="/quantcademy/">Quantcademy</a></li>
            
            <li class="footer-list-link"><a class="link-fade" href="/qstrader/">QSTrader</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/successful-algorithmic-trading-ebook/">Successful Algorithmic Trading</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/advanced-algorithmic-trading-ebook/">Advanced Algorithmic Trading</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/cpp-for-quantitative-finance-ebook/">C++ For Quantitative Finance</a></li>
          </ul>
        </div>

        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">Legal</li>
            <li class="footer-list-link"><a class="link-fade" href="/privacy-policy/">Privacy Policy</a></li>
            <li class="footer-list-link"><a class="link-fade" href="/terms-and-conditions/">Terms &amp; Conditions</a></li>
          </ul>
        </div>

        <div class="col-12 col-sm-12 col-md-6 col-xl-3 mb-1.5">
          <ul class="footer-list">
            <li class="footer-list-title">Social</li>
            <li class="footer-list-link"><a class="link-fade" href="https://twitter.com/quantstart">Twitter</a></li>
            <li class="footer-list-link"><a class="link-fade" href="https://www.youtube.com/channel/UCmVnnZ6Y2TrJtY1eQJN6kWA">YouTube</a></li>
          </ul>
        </div>
      </div>
    </section>

    <div class="row mb-1.5 mt-5">
      <div class="col-12 col-md-9 col-lg-8 col-xl-6">
        <div class="footer-copyright">
          <p>©2012-2023 QuarkGluon Ltd. All rights reserved.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

    
<script src="/static/js/jquery-3.2.1.min.js"></script>
<script src="/static/js/prism.js.min"></script>
<script src="/static/js/bootstrap.min.js"></script>
<script src="/static/js/nav.js"></script>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-5383959-5']);
  _gaq.push(['_trackPageview']);

  (function() {
  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


    
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="/static/js/highcharts/highcharts.js"></script>
<script type="text/javascript">
  num_colours = 10;
</script>
<script src="/static/js/statistics.js"></script>


  </body>
</html>
